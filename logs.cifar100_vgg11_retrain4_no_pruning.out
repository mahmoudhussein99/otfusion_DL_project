/home/mhussein/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
------- Setting up parameters -------
dumping parameters at  /home/mhussein/otfusion_DL_project/exp_cifar100_vgg11_retrain4_no_pruning/configurations
The parameters are: 
 Namespace(n_epochs=300, batch_size_train=64, batch_size_test=1000, learning_rate=0.001, momentum=0.5, log_interval=100, to_download=False, disable_bias=True, dataset='Cifar100', num_models=1, model_name='vgg11_nobias', config_file=None, config_dir='/home/mhussein/otfusion_DL_project/exp_cifar100_vgg11_retrain4_no_pruning/configurations', num_hidden_nodes=400, num_hidden_nodes1=400, num_hidden_nodes2=200, num_hidden_nodes3=100, num_hidden_nodes4=50, sweep_id=90, gpu_id=0, skip_last_layer=False, skip_last_layer_type='average', debug=False, cifar_style_data=False, activation_histograms=False, act_num_samples=100, softmax_temperature=1, activation_mode=None, options_type='generic', deprecated=None, save_result_file='sample_cifar100_vgg11_retrain4_no_pruning.csv', sweep_name='exp_cifar100_vgg11_retrain4_no_pruning', reg=0.01, reg_m=0.001, ground_metric='euclidean', ground_metric_normalize='none', not_squared=True, clip_gm=False, clip_min=0, clip_max=5, tmap_stats=False, ensemble_step=0.5, ground_metric_eff=True, retrain=300, retrain_lr_decay=2.0, retrain_lr_decay_factor=2.0, retrain_lr_decay_epochs='30', retrain_avg_only=False, retrain_geometric_only=True, load_models='./exp_cifar100_vgg11_repeat2_no_pruning/results/exp_cifar100_vgg11_repeat2_no_pruning/', ckpt_type='best', recheck_cifar=True, recheck_acc=False, eval_aligned=False, enable_dropout=False, dump_model=False, dump_final_models=False, correction=True, activation_seed=21, weight_stats=True, sinkhorn_type='normal', geom_ensemble_type='wts', act_bug=False, standardize_acts=False, transform_acts=False, center_acts=False, prelu_acts=True, pool_acts=False, pool_relu=False, normalize_acts=False, normalize_wts=False, gromov=False, gromov_loss='square_loss', tensorboard_root='./tensorboard', tensorboard=False, same_model=-1, dist_normalize=False, update_acts=False, past_correction=True, partial_reshape=False, choice='0 2 4 6 8', diff_init=False, partition_type='labels', personal_class_idx=9, partition_dataloader=-1, personal_split_frac=0.1, exact=True, skip_personal_idx=False, prediction_wts=False, width_ratio=1, proper_marginals=False, retrain_seed=-1, no_random_trainloaders=False, reinit_trainloaders=False, second_model_name=None, print_distances=False, deterministic=False, skip_retrain=-1, importance=None, unbalanced=False, temperature=20, alpha=0.7, dist_epochs=60, handle_skips=False, prune=False, retrain_parents=True, prune_frac=0.5, prune_type='unstructured', experiment_name='cifar100_vgg11_retrain4_no_pruning', timestamp='2024-01-07_11-54-19_113279', rootdir='/home/mhussein/otfusion_DL_project/exp_cifar100_vgg11_retrain4_no_pruning', baseroot='/home/mhussein/otfusion_DL_project', result_dir='/home/mhussein/otfusion_DL_project/exp_cifar100_vgg11_retrain4_no_pruning/results', exp_name='exp_cifar100_vgg11_retrain4_no_pruning', csv_dir='/home/mhussein/otfusion_DL_project/exp_cifar100_vgg11_retrain4_no_pruning/csv')
refactored get_config
------- Loading pre-trained models -------
loading cifar100 dataloaders
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
loading model with idx 0 and checkpoint_type is best
in _make_layers [Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), ReLU(), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), ReLU(), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), ReLU(), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), ReLU(), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), ReLU(), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), ReLU(), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), ReLU(), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), ReLU(), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), AvgPool2d(kernel_size=1, stride=1, padding=0)]
Relu Inplace is  False
model parameters are 
 [torch.Size([64, 3, 3, 3]), torch.Size([128, 64, 3, 3]), torch.Size([256, 128, 3, 3]), torch.Size([256, 256, 3, 3]), torch.Size([512, 256, 3, 3]), torch.Size([512, 512, 3, 3]), torch.Size([512, 512, 3, 3]), torch.Size([512, 512, 3, 3]), torch.Size([100, 512])]
Loading model at path ./exp_cifar100_vgg11_repeat2_no_pruning/results/exp_cifar100_vgg11_repeat2_no_pruning/model_0/best.checkpoint which had accuracy 54.34 and at epoch 65
Done loading all the models

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0474, Accuracy: 5296/10000 (53%)

Rechecked accuracies are  [52.96]
optimizer_learning_rate is  0.0005

--------- Testing in global mode ---------
/home/mhussein/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/home/mhussein/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:149: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0474, Accuracy: 5296/10000 (53%)

check accuracy once again before retraining starts:  52.96
Train Epoch: 1 [0/50000 (0%)]	Loss: 8.969020
Train Epoch: 1 [12800/50000 (26%)]	Loss: 3.811805
Train Epoch: 1 [25600/50000 (51%)]	Loss: 2.165286
Train Epoch: 1 [38400/50000 (77%)]	Loss: 2.790036

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0255, Accuracy: 5199/10000 (52%)

At retrain epoch the accuracy is :  51.99
Train Epoch: 2 [0/50000 (0%)]	Loss: 2.705673
Train Epoch: 2 [12800/50000 (26%)]	Loss: 2.562484
Train Epoch: 2 [25600/50000 (51%)]	Loss: 2.225189
Train Epoch: 2 [38400/50000 (77%)]	Loss: 2.353881

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0230, Accuracy: 5261/10000 (53%)

At retrain epoch the accuracy is :  52.61
Train Epoch: 3 [0/50000 (0%)]	Loss: 2.102777
Train Epoch: 3 [12800/50000 (26%)]	Loss: 2.703087
Train Epoch: 3 [25600/50000 (51%)]	Loss: 1.964916
Train Epoch: 3 [38400/50000 (77%)]	Loss: 1.943807

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0220, Accuracy: 5323/10000 (53%)

A new best at epoch:: 3, with test acc:: 53.23, let's save it!
At retrain epoch the accuracy is :  53.23
Train Epoch: 4 [0/50000 (0%)]	Loss: 1.845856
Train Epoch: 4 [12800/50000 (26%)]	Loss: 1.982366
Train Epoch: 4 [25600/50000 (51%)]	Loss: 1.920764
Train Epoch: 4 [38400/50000 (77%)]	Loss: 2.055622

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0215, Accuracy: 5366/10000 (54%)

A new best at epoch:: 4, with test acc:: 53.66, let's save it!
At retrain epoch the accuracy is :  53.66
Train Epoch: 5 [0/50000 (0%)]	Loss: 2.236768
Train Epoch: 5 [12800/50000 (26%)]	Loss: 2.004360
Train Epoch: 5 [25600/50000 (51%)]	Loss: 2.033511
Train Epoch: 5 [38400/50000 (77%)]	Loss: 2.198406

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0211, Accuracy: 5389/10000 (54%)

A new best at epoch:: 5, with test acc:: 53.89, let's save it!
At retrain epoch the accuracy is :  53.89
Train Epoch: 6 [0/50000 (0%)]	Loss: 1.968728
Train Epoch: 6 [12800/50000 (26%)]	Loss: 2.007599
Train Epoch: 6 [25600/50000 (51%)]	Loss: 1.953245
Train Epoch: 6 [38400/50000 (77%)]	Loss: 2.048217

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0207, Accuracy: 5406/10000 (54%)

A new best at epoch:: 6, with test acc:: 54.06, let's save it!
At retrain epoch the accuracy is :  54.06
Train Epoch: 7 [0/50000 (0%)]	Loss: 1.775160
Train Epoch: 7 [12800/50000 (26%)]	Loss: 1.878793
Train Epoch: 7 [25600/50000 (51%)]	Loss: 1.777483
Train Epoch: 7 [38400/50000 (77%)]	Loss: 1.624233

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0205, Accuracy: 5420/10000 (54%)

A new best at epoch:: 7, with test acc:: 54.2, let's save it!
At retrain epoch the accuracy is :  54.2
Train Epoch: 8 [0/50000 (0%)]	Loss: 1.839295
Train Epoch: 8 [12800/50000 (26%)]	Loss: 1.851963
Train Epoch: 8 [25600/50000 (51%)]	Loss: 1.959486
Train Epoch: 8 [38400/50000 (77%)]	Loss: 2.074718

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0203, Accuracy: 5426/10000 (54%)

A new best at epoch:: 8, with test acc:: 54.26, let's save it!
At retrain epoch the accuracy is :  54.26
Train Epoch: 9 [0/50000 (0%)]	Loss: 2.052713
Train Epoch: 9 [12800/50000 (26%)]	Loss: 2.095012
Train Epoch: 9 [25600/50000 (51%)]	Loss: 1.751042
Train Epoch: 9 [38400/50000 (77%)]	Loss: 2.092624

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0201, Accuracy: 5432/10000 (54%)

A new best at epoch:: 9, with test acc:: 54.32, let's save it!
At retrain epoch the accuracy is :  54.32
Train Epoch: 10 [0/50000 (0%)]	Loss: 1.543640
Train Epoch: 10 [12800/50000 (26%)]	Loss: 1.899513
Train Epoch: 10 [25600/50000 (51%)]	Loss: 1.693824
Train Epoch: 10 [38400/50000 (77%)]	Loss: 2.115613

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0199, Accuracy: 5459/10000 (55%)

A new best at epoch:: 10, with test acc:: 54.59, let's save it!
At retrain epoch the accuracy is :  54.59
Train Epoch: 11 [0/50000 (0%)]	Loss: 1.832809
Train Epoch: 11 [12800/50000 (26%)]	Loss: 1.629155
Train Epoch: 11 [25600/50000 (51%)]	Loss: 1.775160
Train Epoch: 11 [38400/50000 (77%)]	Loss: 2.049448

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0198, Accuracy: 5470/10000 (55%)

A new best at epoch:: 11, with test acc:: 54.7, let's save it!
At retrain epoch the accuracy is :  54.7
Train Epoch: 12 [0/50000 (0%)]	Loss: 2.059946
Train Epoch: 12 [12800/50000 (26%)]	Loss: 1.825591
Train Epoch: 12 [25600/50000 (51%)]	Loss: 1.575030
Train Epoch: 12 [38400/50000 (77%)]	Loss: 1.656419

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0197, Accuracy: 5475/10000 (55%)

A new best at epoch:: 12, with test acc:: 54.75, let's save it!
At retrain epoch the accuracy is :  54.75
Train Epoch: 13 [0/50000 (0%)]	Loss: 1.633992
Train Epoch: 13 [12800/50000 (26%)]	Loss: 1.946935
Train Epoch: 13 [25600/50000 (51%)]	Loss: 2.061959
Train Epoch: 13 [38400/50000 (77%)]	Loss: 1.890297

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0196, Accuracy: 5477/10000 (55%)

A new best at epoch:: 13, with test acc:: 54.77, let's save it!
At retrain epoch the accuracy is :  54.77
Train Epoch: 14 [0/50000 (0%)]	Loss: 2.278243
Train Epoch: 14 [12800/50000 (26%)]	Loss: 1.816519
Train Epoch: 14 [25600/50000 (51%)]	Loss: 2.003363
Train Epoch: 14 [38400/50000 (77%)]	Loss: 1.518135

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0195, Accuracy: 5500/10000 (55%)

A new best at epoch:: 14, with test acc:: 55.0, let's save it!
At retrain epoch the accuracy is :  55.0
Train Epoch: 15 [0/50000 (0%)]	Loss: 1.842883
Train Epoch: 15 [12800/50000 (26%)]	Loss: 1.831786
Train Epoch: 15 [25600/50000 (51%)]	Loss: 2.103767
Train Epoch: 15 [38400/50000 (77%)]	Loss: 1.658014

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0194, Accuracy: 5512/10000 (55%)

A new best at epoch:: 15, with test acc:: 55.12, let's save it!
At retrain epoch the accuracy is :  55.12
Train Epoch: 16 [0/50000 (0%)]	Loss: 1.478585
Train Epoch: 16 [12800/50000 (26%)]	Loss: 1.894742
Train Epoch: 16 [25600/50000 (51%)]	Loss: 1.563830
Train Epoch: 16 [38400/50000 (77%)]	Loss: 1.727078

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0193, Accuracy: 5518/10000 (55%)

A new best at epoch:: 16, with test acc:: 55.18, let's save it!
At retrain epoch the accuracy is :  55.18
Train Epoch: 17 [0/50000 (0%)]	Loss: 1.684452
Train Epoch: 17 [12800/50000 (26%)]	Loss: 1.750332
Train Epoch: 17 [25600/50000 (51%)]	Loss: 1.468333
Train Epoch: 17 [38400/50000 (77%)]	Loss: 1.599358

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0193, Accuracy: 5529/10000 (55%)

A new best at epoch:: 17, with test acc:: 55.29, let's save it!
At retrain epoch the accuracy is :  55.29
Train Epoch: 18 [0/50000 (0%)]	Loss: 1.710603
Train Epoch: 18 [12800/50000 (26%)]	Loss: 1.757841
Train Epoch: 18 [25600/50000 (51%)]	Loss: 1.761049
Train Epoch: 18 [38400/50000 (77%)]	Loss: 1.695626

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0192, Accuracy: 5531/10000 (55%)

A new best at epoch:: 18, with test acc:: 55.31, let's save it!
At retrain epoch the accuracy is :  55.31
Train Epoch: 19 [0/50000 (0%)]	Loss: 1.709933
Train Epoch: 19 [12800/50000 (26%)]	Loss: 1.551760
Train Epoch: 19 [25600/50000 (51%)]	Loss: 1.749008
Train Epoch: 19 [38400/50000 (77%)]	Loss: 1.664258

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0191, Accuracy: 5536/10000 (55%)

A new best at epoch:: 19, with test acc:: 55.36, let's save it!
At retrain epoch the accuracy is :  55.36
Train Epoch: 20 [0/50000 (0%)]	Loss: 1.687872
Train Epoch: 20 [12800/50000 (26%)]	Loss: 1.874198
Train Epoch: 20 [25600/50000 (51%)]	Loss: 1.629635
Train Epoch: 20 [38400/50000 (77%)]	Loss: 1.630659

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0190, Accuracy: 5542/10000 (55%)

A new best at epoch:: 20, with test acc:: 55.42, let's save it!
At retrain epoch the accuracy is :  55.42
Train Epoch: 21 [0/50000 (0%)]	Loss: 1.766577
Train Epoch: 21 [12800/50000 (26%)]	Loss: 1.902062
Train Epoch: 21 [25600/50000 (51%)]	Loss: 1.784923
Train Epoch: 21 [38400/50000 (77%)]	Loss: 1.531070

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0190, Accuracy: 5550/10000 (56%)

A new best at epoch:: 21, with test acc:: 55.5, let's save it!
At retrain epoch the accuracy is :  55.5
Train Epoch: 22 [0/50000 (0%)]	Loss: 1.851468
Train Epoch: 22 [12800/50000 (26%)]	Loss: 1.660428
Train Epoch: 22 [25600/50000 (51%)]	Loss: 1.502056
Train Epoch: 22 [38400/50000 (77%)]	Loss: 1.609318

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0189, Accuracy: 5546/10000 (55%)

At retrain epoch the accuracy is :  55.46
Train Epoch: 23 [0/50000 (0%)]	Loss: 1.545163
Train Epoch: 23 [12800/50000 (26%)]	Loss: 1.724656
Train Epoch: 23 [25600/50000 (51%)]	Loss: 1.848992
Train Epoch: 23 [38400/50000 (77%)]	Loss: 1.435382

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0189, Accuracy: 5559/10000 (56%)

A new best at epoch:: 23, with test acc:: 55.59, let's save it!
At retrain epoch the accuracy is :  55.59
Train Epoch: 24 [0/50000 (0%)]	Loss: 1.689295
Train Epoch: 24 [12800/50000 (26%)]	Loss: 1.329162
Train Epoch: 24 [25600/50000 (51%)]	Loss: 2.073930
Train Epoch: 24 [38400/50000 (77%)]	Loss: 1.599907

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0188, Accuracy: 5572/10000 (56%)

A new best at epoch:: 24, with test acc:: 55.72, let's save it!
At retrain epoch the accuracy is :  55.72
Train Epoch: 25 [0/50000 (0%)]	Loss: 1.487679
Train Epoch: 25 [12800/50000 (26%)]	Loss: 1.776447
Train Epoch: 25 [25600/50000 (51%)]	Loss: 1.413507
Train Epoch: 25 [38400/50000 (77%)]	Loss: 1.637944

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0188, Accuracy: 5574/10000 (56%)

A new best at epoch:: 25, with test acc:: 55.74, let's save it!
At retrain epoch the accuracy is :  55.74
Train Epoch: 26 [0/50000 (0%)]	Loss: 1.726360
Train Epoch: 26 [12800/50000 (26%)]	Loss: 1.590623
Train Epoch: 26 [25600/50000 (51%)]	Loss: 1.337149
Train Epoch: 26 [38400/50000 (77%)]	Loss: 1.396458

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0187, Accuracy: 5558/10000 (56%)

At retrain epoch the accuracy is :  55.58
Train Epoch: 27 [0/50000 (0%)]	Loss: 1.542435
Train Epoch: 27 [12800/50000 (26%)]	Loss: 1.656634
Train Epoch: 27 [25600/50000 (51%)]	Loss: 1.563592
Train Epoch: 27 [38400/50000 (77%)]	Loss: 1.638915

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0187, Accuracy: 5583/10000 (56%)

A new best at epoch:: 27, with test acc:: 55.83, let's save it!
At retrain epoch the accuracy is :  55.83
Train Epoch: 28 [0/50000 (0%)]	Loss: 1.665076
Train Epoch: 28 [12800/50000 (26%)]	Loss: 1.520752
Train Epoch: 28 [25600/50000 (51%)]	Loss: 1.426101
Train Epoch: 28 [38400/50000 (77%)]	Loss: 1.557562

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0186, Accuracy: 5575/10000 (56%)

At retrain epoch the accuracy is :  55.75
Train Epoch: 29 [0/50000 (0%)]	Loss: 1.550331
Train Epoch: 29 [12800/50000 (26%)]	Loss: 1.289029
Train Epoch: 29 [25600/50000 (51%)]	Loss: 1.488454
Train Epoch: 29 [38400/50000 (77%)]	Loss: 1.604663

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0186, Accuracy: 5567/10000 (56%)

At retrain epoch the accuracy is :  55.67
Train Epoch: 30 [0/50000 (0%)]	Loss: 1.544299
Train Epoch: 30 [12800/50000 (26%)]	Loss: 1.529306
Train Epoch: 30 [25600/50000 (51%)]	Loss: 1.738175
Train Epoch: 30 [38400/50000 (77%)]	Loss: 1.166516

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0186, Accuracy: 5580/10000 (56%)

At retrain epoch the accuracy is :  55.8
Train Epoch: 31 [0/50000 (0%)]	Loss: 1.722026
Train Epoch: 31 [12800/50000 (26%)]	Loss: 1.664395
Train Epoch: 31 [25600/50000 (51%)]	Loss: 1.422893
Train Epoch: 31 [38400/50000 (77%)]	Loss: 1.601573

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0186, Accuracy: 5582/10000 (56%)

At retrain epoch the accuracy is :  55.82
Train Epoch: 32 [0/50000 (0%)]	Loss: 1.611446
Train Epoch: 32 [12800/50000 (26%)]	Loss: 1.480538
Train Epoch: 32 [25600/50000 (51%)]	Loss: 1.797344
Train Epoch: 32 [38400/50000 (77%)]	Loss: 1.716828

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0186, Accuracy: 5584/10000 (56%)

A new best at epoch:: 32, with test acc:: 55.84, let's save it!
At retrain epoch the accuracy is :  55.84
Train Epoch: 33 [0/50000 (0%)]	Loss: 1.760593
Train Epoch: 33 [12800/50000 (26%)]	Loss: 1.304397
Train Epoch: 33 [25600/50000 (51%)]	Loss: 1.572415
Train Epoch: 33 [38400/50000 (77%)]	Loss: 1.595797

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0185, Accuracy: 5589/10000 (56%)

A new best at epoch:: 33, with test acc:: 55.89, let's save it!
At retrain epoch the accuracy is :  55.89
Train Epoch: 34 [0/50000 (0%)]	Loss: 1.365977
Train Epoch: 34 [12800/50000 (26%)]	Loss: 1.653948
Train Epoch: 34 [25600/50000 (51%)]	Loss: 1.340993
Train Epoch: 34 [38400/50000 (77%)]	Loss: 1.658795

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0185, Accuracy: 5588/10000 (56%)

At retrain epoch the accuracy is :  55.88
Train Epoch: 35 [0/50000 (0%)]	Loss: 1.612600
Train Epoch: 35 [12800/50000 (26%)]	Loss: 1.675142
Train Epoch: 35 [25600/50000 (51%)]	Loss: 1.236734
Train Epoch: 35 [38400/50000 (77%)]	Loss: 1.292681

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0185, Accuracy: 5597/10000 (56%)

A new best at epoch:: 35, with test acc:: 55.97, let's save it!
At retrain epoch the accuracy is :  55.97
Train Epoch: 36 [0/50000 (0%)]	Loss: 1.446668
Train Epoch: 36 [12800/50000 (26%)]	Loss: 1.535860
Train Epoch: 36 [25600/50000 (51%)]	Loss: 1.227919
Train Epoch: 36 [38400/50000 (77%)]	Loss: 1.503116

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0185, Accuracy: 5588/10000 (56%)

At retrain epoch the accuracy is :  55.88
Train Epoch: 37 [0/50000 (0%)]	Loss: 1.744684
Train Epoch: 37 [12800/50000 (26%)]	Loss: 1.710836
Train Epoch: 37 [25600/50000 (51%)]	Loss: 1.395505
Train Epoch: 37 [38400/50000 (77%)]	Loss: 1.525837

--------- Testing in global mode ---------
size of test_loader dataset:  10000

Test set: Avg. loss: 0.0185, Accuracy: 5584/10000 (56%)

At retrain epoch the accuracy is :  55.84
slurmstepd: error: *** STEP 4939.0 ON studgpu-node09 CANCELLED AT 2024-01-07T12:34:17 ***
